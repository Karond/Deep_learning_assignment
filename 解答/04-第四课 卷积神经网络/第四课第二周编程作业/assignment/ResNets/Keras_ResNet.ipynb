{"cells":[{"outputs":[{"output_type":"stream","text":"datasets7965\r\n","name":"stdout"}],"execution_count":1,"source":["# 查看当前挂载的数据集目录\n","!ls /home/kesci/input/"],"cell_type":"code","metadata":{"collapsed":false,"id":"D48140050E0C4C6B80CA08D102D035BF","scrolled":false},"hide_input":false},{"outputs":[{"output_type":"stream","text":"all.pth  data\r\n","name":"stdout"}],"execution_count":2,"source":["# 查看个人持久化工作区文件\n","!ls /home/kesci/work/"],"cell_type":"code","metadata":{"collapsed":false,"id":"4409463B00214E19824D45A01FCE044F","scrolled":false},"hide_input":false},{"outputs":[],"execution_count":3,"source":["# 显示cell运行时长\n","%load_ext klab-autotime"],"cell_type":"code","metadata":{"collapsed":false,"id":"57C0EDFBB199468B8C24E6825B0FC30A","scrolled":false},"hide_input":false},{"metadata":{"id":"4BACF6F92B9E4A908BC478091445BBB9","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n/opt/conda/lib/python3.5/site-packages/matplotlib/font_manager.py:278: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n  'Matplotlib is building the font cache using fc-list. '\n","name":"stderr"},{"output_type":"stream","text":"time: 53.3 s\n","name":"stdout"}],"hide_input":false,"source":["import numpy as np\r\n","import tensorflow as tf\r\n","from keras import layers\r\n","from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\r\n","from keras.models import Model, load_model\r\n","from keras.preprocessing import image\r\n","from keras.utils import layer_utils\r\n","from keras.utils.data_utils import get_file\r\n","from keras.applications.imagenet_utils import preprocess_input\r\n","import pydot\r\n","from IPython.display import SVG\r\n","from keras.utils.vis_utils import model_to_dot\r\n","from keras.utils import plot_model\r\n","import os\r\n","import h5py\r\n","import math\r\n","from keras.initializers import glorot_uniform\r\n","import scipy.misc\r\n","from matplotlib.pyplot import imshow\r\n","%matplotlib inline\r\n","\r\n","import keras.backend as K\r\n","K.set_image_data_format('channels_last')\r\n","K.set_learning_phase(1)"],"execution_count":4},{"metadata":{"id":"804483B09538468081FFD63CDFDB4157","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"time: 3.07 ms\n","name":"stdout"}],"hide_input":false,"source":["def load_dataset():\n","    train_dataset = h5py.File('/home/kesci/input/datasets7965/train_signs.h5', \"r\")\n","    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n","    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n","\n","    test_dataset = h5py.File('/home/kesci/input/datasets7965/test_signs.h5', \"r\")\n","    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n","    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n","\n","    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n","    \n","    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n","    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n","    \n","    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes\n",""],"execution_count":5},{"metadata":{"id":"2FC0F6957CDB41DB9214F3DE8C5EC00F","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"time: 17.5 ms\n","name":"stdout"}],"hide_input":false,"source":["def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n","    \"\"\"\n","    Creates a list of random minibatches from (X, Y)\n","    \n","    Arguments:\n","    X -- input data, of shape (input size, number of examples) (m, Hi, Wi, Ci)\n","    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples) (m, n_y)\n","    mini_batch_size - size of the mini-batches, integer\n","    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n","    \n","    Returns:\n","    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n","    \"\"\"\n","    \n","    m = X.shape[0]                  # number of training examples\n","    mini_batches = []\n","    np.random.seed(seed)\n","    \n","    # Step 1: Shuffle (X, Y)\n","    permutation = list(np.random.permutation(m))\n","    shuffled_X = X[permutation,:,:,:]\n","    shuffled_Y = Y[permutation,:]\n","\n","    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n","    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n","    for k in range(0, num_complete_minibatches):\n","        mini_batch_X = shuffled_X[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:,:,:]\n","        mini_batch_Y = shuffled_Y[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:]\n","        mini_batch = (mini_batch_X, mini_batch_Y)\n","        mini_batches.append(mini_batch)\n","    \n","    # Handling the end case (last mini-batch < mini_batch_size)\n","    if m % mini_batch_size != 0:\n","        mini_batch_X = shuffled_X[num_complete_minibatches * mini_batch_size : m,:,:,:]\n","        mini_batch_Y = shuffled_Y[num_complete_minibatches * mini_batch_size : m,:]\n","        mini_batch = (mini_batch_X, mini_batch_Y)\n","        mini_batches.append(mini_batch)\n","    \n","    return mini_batches"],"execution_count":6},{"metadata":{"id":"E9461946801846B28896069A48AD71A9","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"time: 1.8 ms\n","name":"stdout"}],"hide_input":false,"source":["def convert_to_one_hot(Y, C):\n","    Y = np.eye(C)[Y.reshape(-1)].T\n","    return Y"],"execution_count":7},{"metadata":{"id":"FB215EF0931B41E9A088B76A572CFF97","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"time: 21.1 ms\n","name":"stdout"}],"hide_input":false,"source":["X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()"],"execution_count":8},{"metadata":{"id":"BDE599CA3B17478984D344C8F771B896","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"number of training examples = 1080\nnumber of test examples = 120\nX_train shape: (1080, 64, 64, 3)\nY_train shape: (1080, 6)\nX_test shape: (120, 64, 64, 3)\nY_test shape: (120, 6)\ntime: 102 ms\n","name":"stdout"}],"hide_input":false,"source":["X_train = X_train_orig/255.\r\n","X_test = X_test_orig/255.\r\n","Y_train = convert_to_one_hot(Y_train_orig, 6).T\r\n","Y_test = convert_to_one_hot(Y_test_orig, 6).T\r\n","\r\n","print (\"number of training examples = \" + str(X_train.shape[0]))\r\n","print (\"number of test examples = \" + str(X_test.shape[0]))\r\n","print (\"X_train shape: \" + str(X_train.shape))\r\n","print (\"Y_train shape: \" + str(Y_train.shape))\r\n","print (\"X_test shape: \" + str(X_test.shape))\r\n","print (\"Y_test shape: \" + str(Y_test.shape))"],"execution_count":9},{"metadata":{"id":"DCF5D30946B548B4904A8A9FEC3E56D0","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"time: 4.41 ms\n","name":"stdout"}],"hide_input":false,"source":["def identity_block(X, f, filters, stage, block):\r\n","\r\n","    \r\n","    conv_name_base = 'res' + str(stage) + block + '_branch'\r\n","    bn_name_base = 'bn' + str(stage) + block + '_branch'\r\n","    \r\n","    F1, F2, F3 = filters\r\n","    \r\n","    X_shortcut = X\r\n","    \r\n","    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\r\n","    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\r\n","    X = Activation('relu')(X)\r\n","    \r\n","    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\r\n","    X = BatchNormalization(axis=3, name = bn_name_base + '2b')(X)\r\n","    X = Activation('relu')(X)\r\n","\r\n","    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\r\n","    X = BatchNormalization(axis=3, name = bn_name_base + '2c')(X)\r\n","\r\n","    X = layers.add([X, X_shortcut])\r\n","    X = Activation('relu')(X)\r\n","\r\n","    \r\n","    return X"],"execution_count":10},{"metadata":{"id":"2E30D677ECC444F08C2523C903ABB82C","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"time: 4.92 ms\n","name":"stdout"}],"hide_input":false,"source":["def convolutional_block(X, f, filters, stage, block, s = 2):\r\n","\r\n","    \r\n","    conv_name_base = 'res' + str(stage) + block + '_branch'\r\n","    bn_name_base = 'bn' + str(stage) + block + '_branch'\r\n","    \r\n","    F1, F2, F3 = filters\r\n","    \r\n","    X_shortcut = X\r\n","\r\n","\r\n","    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a', padding='valid', kernel_initializer = glorot_uniform(seed=0))(X)\r\n","    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\r\n","    X = Activation('relu')(X)\r\n","    \r\n","    X = Conv2D(F2, (f, f), strides = (1, 1), name = conv_name_base + '2b',padding='same', kernel_initializer = glorot_uniform(seed=0))(X)\r\n","    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\r\n","    X = Activation('relu')(X)\r\n","\r\n","    X = Conv2D(F3, (1, 1), strides = (1, 1), name = conv_name_base + '2c',padding='valid', kernel_initializer = glorot_uniform(seed=0))(X)\r\n","    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\r\n","\r\n","    X_shortcut = Conv2D(F3, (1, 1), strides = (s, s), name = conv_name_base + '1',padding='valid', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\r\n","    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\r\n","\r\n","    X = layers.add([X, X_shortcut])\r\n","    X = Activation('relu')(X)\r\n","\r\n","    return X"],"execution_count":11},{"metadata":{"id":"279DA17ACD7A4CFF8A15EC43DBC3676F","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"time: 59.6 ms\n","name":"stdout"}],"hide_input":false,"source":["def ResNet50(input_shape = (64, 64, 3), classes = 6):\r\n","    X_input = Input(input_shape)\r\n","\r\n","    \r\n","    X = ZeroPadding2D((3, 3))(X_input)\r\n","    \r\n","    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\r\n","    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\r\n","    X = Activation('relu')(X)\r\n","    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\r\n","\r\n","    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\r\n","    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\r\n","    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\r\n","\r\n","    X = convolutional_block(X, f = 3, filters=[128,128,512], stage = 3, block='a', s = 2)\r\n","    X = identity_block(X, f = 3, filters=[128,128,512], stage= 3, block='b')\r\n","    X = identity_block(X, f = 3, filters=[128,128,512], stage= 3, block='c')\r\n","    X = identity_block(X, f = 3, filters=[128,128,512], stage= 3, block='d')\r\n","\r\n","    X = convolutional_block(X, f = 3, filters=[256, 256, 1024], block='a', stage=4, s = 2)\r\n","    X = identity_block(X, f = 3, filters=[256, 256, 1024], block='b', stage=4)\r\n","    X = identity_block(X, f = 3, filters=[256, 256, 1024], block='c', stage=4)\r\n","    X = identity_block(X, f = 3, filters=[256, 256, 1024], block='d', stage=4)\r\n","    X = identity_block(X, f = 3, filters=[256, 256, 1024], block='e', stage=4)\r\n","    X = identity_block(X, f = 3, filters=[256, 256, 1024], block='f', stage=4)\r\n","\r\n","    X = convolutional_block(X, f = 3, filters=[512, 512, 2048], stage=5, block='a', s = 2)\r\n","    \r\n","    X = identity_block(X, f = 3, filters=[256, 256, 2048], stage=5, block='b')\r\n","    X = identity_block(X, f = 3, filters=[256, 256, 2048], stage=5, block='c')\r\n","\r\n","    X = AveragePooling2D(pool_size=(2,2))(X)\r\n","    \r\n","\r\n","    X = Flatten()(X)\r\n","    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\r\n","    \r\n","    \r\n","    model = Model(inputs = X_input, outputs = X, name='ResNet50')\r\n","\r\n","    return model"],"execution_count":12},{"metadata":{"id":"1A958D3FE9E143189F27E262B16CE597","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"time: 6.25 s\n","name":"stdout"}],"hide_input":false,"source":["model = ResNet50(input_shape = (64, 64, 3), classes = 6)"],"execution_count":13},{"metadata":{"id":"C303DAC967E7473CBCB841F5B5DE76D9","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"time: 33.6 ms\n","name":"stdout"}],"hide_input":false,"source":["model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"],"execution_count":14},{"metadata":{"id":"520E65D0E0A34F598700DF45F913F41C","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"Epoch 1/20\n1080/1080 [==============================] - 149s 138ms/step - loss: 2.5428 - acc: 0.2537\nEpoch 2/20\n1080/1080 [==============================] - 141s 130ms/step - loss: 1.9078 - acc: 0.3176\nEpoch 3/20\n1080/1080 [==============================] - 141s 131ms/step - loss: 1.5978 - acc: 0.4185\nEpoch 4/20\n1080/1080 [==============================] - 141s 131ms/step - loss: 1.3389 - acc: 0.4954\nEpoch 5/20\n1080/1080 [==============================] - 141s 131ms/step - loss: 0.9457 - acc: 0.5935\nEpoch 6/20\n1080/1080 [==============================] - 141s 131ms/step - loss: 0.8631 - acc: 0.7046\nEpoch 7/20\n1080/1080 [==============================] - 141s 131ms/step - loss: 0.9094 - acc: 0.7352\nEpoch 8/20\n1080/1080 [==============================] - 141s 131ms/step - loss: 0.6506 - acc: 0.7898\nEpoch 9/20\n1080/1080 [==============================] - 141s 131ms/step - loss: 0.4246 - acc: 0.8676\nEpoch 10/20\n1080/1080 [==============================] - 141s 131ms/step - loss: 0.2470 - acc: 0.9204\nEpoch 11/20\n1080/1080 [==============================] - 141s 131ms/step - loss: 0.2273 - acc: 0.9398\nEpoch 12/20\n1080/1080 [==============================] - 141s 131ms/step - loss: 0.2185 - acc: 0.9361\nEpoch 13/20\n1080/1080 [==============================] - 141s 130ms/step - loss: 0.1351 - acc: 0.9611\nEpoch 14/20\n1080/1080 [==============================] - 141s 131ms/step - loss: 0.1669 - acc: 0.9593\nEpoch 15/20\n1080/1080 [==============================] - 141s 131ms/step - loss: 0.1033 - acc: 0.9769\nEpoch 16/20\n1080/1080 [==============================] - 141s 131ms/step - loss: 0.1186 - acc: 0.9630\nEpoch 17/20\n1080/1080 [==============================] - 141s 131ms/step - loss: 0.0660 - acc: 0.9769\nEpoch 18/20\n1080/1080 [==============================] - 141s 131ms/step - loss: 0.1036 - acc: 0.9676\nEpoch 19/20\n1080/1080 [==============================] - 141s 130ms/step - loss: 0.0811 - acc: 0.9806\nEpoch 20/20\n1080/1080 [==============================] - 141s 131ms/step - loss: 0.1958 - acc: 0.9426\n","name":"stdout"},{"output_type":"execute_result","metadata":{},"data":{"text/plain":"<keras.callbacks.History at 0x7f43688727b8>"}},{"output_type":"stream","text":"time: 47min 15s\n","name":"stdout"}],"hide_input":false,"source":["model.fit(X_train, Y_train, epochs = 20, batch_size = 32)"],"execution_count":15},{"metadata":{"id":"4156D89616EF464080A024CFA548681F","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"hide_input":false,"source":["preds = model.evaluate(X_test, Y_test)\r\n","print (\"Loss = \" + str(preds[0]))\r\n","print (\"Test Accuracy = \" + str(preds[1]))"],"execution_count":null}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python","nbconvert_exporter":"python","file_extension":".py","version":"3.5.2","pygments_lexer":"ipython3"}},"nbformat":4,"nbformat_minor":0}